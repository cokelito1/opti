\documentclass[a4paper,oneside,10.5pt]{USMArt}

\usepackage{personal}
\usepackage{comment}
\usepackage[letterpaper, left=2cm, right=2cm]{geometry}

\title{Tarea I - Optimización y Control}
\sigla{MAT-379 }
\ramo{Optimización y Control}
\profesor{Patricio Guzman}
\semestre{2025-1}
\author{Jorge Bravo}

\begin{document}
\maketitle

\begin{sol}
  Sea $P = \{J(y) \; | \; y \in C\}$, donde $C = \{y \in \mathcal{C}^{1} \; | \; y(0) = 0, y(1) = 1\}$
  y

  \begin{equation*}
    J(y) = \int_{1}^{\frac12} |y(x)| dx + \int_{\frac12}^1 |y'(x)| dx
  \end{equation*}

  \begin{enumerate}
    \item Notemos que el conjunto C es no vació, pues la función $\text{Id}_{[0, 1]}$ cumple las condiciones para
      pertenecer a este. Luego podemos evaluar el funcional en $\text{Id}_{[0, 1]}$ y nos dará un numero pues estamos
      integrando una función continua sobre un compacto. Notemos que $|y(x)| \geq 0$ e $|y'(x)| \geq 0$
      para todo $y \in C$ y $x \in [0, 1]$, por lo tanto tenemos que $\forall y \in C, J(y) \geq 0$.
      Dado que mostramos que el conjunto $P$ es no vacío y tiene una cota inferior, existe $\inf P \in \RR$
      por axioma del supremo e ínfimo.

    \item Dado que en el paso anterior mostramos que $0$ es un cota inferior para el conjunto $P$ y el
     ínfimo es la mayor de las cotas superiores tenemos que

    \begin{equation*}
      0 \leq \inf P
    \end{equation*}

    \item La intuición nos dice que una función que minimiza $J$ que esta fuera del conjunto $C$
          es la indicatriz del conjunto $[\frac12, 1]$, construyamos una sucesión de funciones
          que la aproximen desde $C$. Consideremos la siguiente sucesión para $n \geq 3$

    \begin{equation*}
      f_{n}(x) = \begin{cases}
                   0 & \text{ si } x \in [0, \frac12 - \frac1n)\\
                   P_{n}(x) & \text{ si } x \in [\frac12 - \frac1n, \frac12]\\
                   1 & \text{ si } x \in (\frac12, 1]
                 \end{cases}
    \end{equation*}

    Donde $P_{n}$ sera un polinomio que a de cumplir con las siguientes condiciones
    \begin{align*}
      P_{n}(\frac12) &= 1\\
      P_{n}'(\frac12) &= 0\\
      P_{n}(\frac12 - \frac1n) &= 0\\
      P_{n}'(\frac12 - \frac1n) &= 0
    \end{align*}

    Pues si $P_{n}$ cumple con esas cuatro condiciones, entonces $f_{n} \in C$, dado que están
    de acuerdo en la derivada en los puntos de pegado y en el valor de la función también.
    Notemos que por construcción $f_{n}(0) = 0$ y $f_{n}(1) = 1$.

    Dado que tenemos $4$ condiciones sobre $P_{n}$, un polinomio de grado $3$ sera suficiente.
    Consideraremos $P_{n}(x) = a(x - \frac12)^{3} + b(x - \frac12)^{2} + c(x - \frac12) + d$.
    Luego las cuatro condiciones se transforman en lo siguiente

    \begin{align*}
       d &= 1\\
       c &= 0\\
       -\frac{a}{n^{3}} + \frac{b}{n^{2}} + 1 &= 0\\
       \frac{3a}{n^{2}} - \frac{2b}{n} &= 0
    \end{align*}

    Resolviendo el sistema llegamos al polinomio $P_{n}$, el cual por construcción satisface todo lo que necesitábamos.

    \begin{equation*}
      P_{n}(x) = -2n^{3}(x - \frac12)^{3} - 3n^{2}(x - \frac12)^{2} + 1
    \end{equation*}

    Luego $f_{n} \in C$. Probemos que en efecto $(f_{n})_{n \geq 3}$ es una sucesión minimizante.

    Notemos que

    \begin{align*}
      J(f_{n}) &= \int_{0}^{\frac{1}{2}} |f_{n}(x)| dx + \int_{\frac12}^{1} |f_{n}(x)'|dx\\
               &= \int_{0}^{\frac12 - \frac1n} 0 dx + \int_{\frac12 - \frac1n}^{\frac12} |P_{n}(x)| dx + \int_{\frac12}^{1} 0 dx\\
               &= \int_{\frac12 - \frac1n}^{\frac12} |P_{n}(x)| dx
    \end{align*}

    Dado que $P_{n}'$ es una cuadrática con coeficiente líder negativo, y sabemos
    que $P_{n}'(\frac12 - \frac1n) = 0 = P_{n}'(\frac12)$, tenemos
    que $\forall x \in [\frac12  - \frac1n, \frac12], P_{n}'(x) \geq 0$,
    es decir $P_{n}$ es creciente en ese intervalo, dado que $P_{n}(\frac12 - \frac1n) = 0$, tenemos que

    \begin{equation*}
      \forall x \in [\frac12 - \frac1n, \frac12], P_{n}(x) \geq 0
    \end{equation*}

    Luego seguimos con el calculo
    \begin{align*}
      J(f_{n}) &= \int_{\frac12 - \frac1n}^{\frac12} P_{n}(x) dx\\
               &= \int_{\frac12 - \frac1n}^{\frac12} -2n^{3}(x - \frac12)^{3} - 3n^{2}(x - \frac12)^{2} + 1 dx\\
               &= -\frac{1}{2}n^{3}(x - \frac12)^{4}|_{x = \frac12 - \frac1n}^{x = \frac12} - n^{2}(x - \frac12)^{3}|_{x = \frac12 - \frac1n}^{x = \frac12} + \frac1n\\
               &= \frac{1}{2n} - \frac{1}{n} + \frac{1}{n}\\
               &= \frac{1}{2n}
    \end{align*}

    Por lo tanto obtenemos que

    \begin{equation*}
      \lim_{n \to \infty} J(f_{n}) = 0
    \end{equation*}

    Es decir $(f_{n})_{n \geq 3}$ es una sucesión minimizante.

    \item No, no existe $\overline{y} \in C$ que minimice $J$, si suponemos que existe, entonces

    \begin{equation*}
      J(\overline{y}) = 0
    \end{equation*}

    Pues existe la sucesión minimizante a $0$ que construimos en el paso anterior y por tanto
    demostramos que $\inf P = 0$. Dado que $J(\overline{y})$ es la suma de dos cantidades positivas
    y tiene que ser igual a $0$, necesariamente cada una a de ser $0$.

    Notemos que

    \begin{equation*}
      \int_{0}^{\frac12} |\overline{y}(x)| dx = 0 \implies \forall x \in [0, \frac12], |\overline{y}(x)| = 0 \implies \forall x \in [0, \frac12], \overline{y}(x) = 0
    \end{equation*}

    Pues la cantidad de adentro es positiva y por tanto $0$ c.t.p. y por continuidad, en todas partes.
    Por lo tanto tenemos que $\overline{y}|_{[0, \frac12]} \equiv 0$.
    Análogamente, dado que estamos suponiendo $\overline{y} \in C$, $\overline{y}'$ es continua y por
    tanto su valor absoluto igual. Por el argumento anterior $\overline{y}'|_{[\frac12, 1]} \equiv 0$,
    por lo tanto $\overline{y}|_{[\frac12, 1]} \equiv c$ para algún $c \in \RR$,
    dado que $\overline{y}(1) = 1 \implies c = 1$.
    Esto es una contradicción pues entonces $0 = \overline{y}(\frac12) = 1$.
  \end{enumerate}
\end{sol}

\begin{sol}
  Usaremos el lema de Fermat. Supongamos que $y \in Y$ satisface el problema de minimización.
  Consideraremos una perturbación $h \in \mathcal{C}_{0}^{2}([0, L])$. Luego tenemos que

  \begin{equation*}
    \lim_{\varepsilon \to 0} \frac{J(y + \varepsilon h) - J(y)}{h} = \frac{d}{d \varepsilon} J(y + \varepsilon h)\big|_{\varepsilon = 0} = 0
  \end{equation*}

  Hagamos el calculo
  \begin{align*}
    \frac{d}{d \varepsilon} J(y + \varepsilon h) &= \frac{d}{d \varepsilon}(\frac12 \int_{0}^{L} EI(y''(x) + \varepsilon h''(x))^{2} dx - \int_{0}^{L} q(x)(y(x) + \varepsilon h(x)))\\
  \end{align*}

  Dada la regularidad de las funciones con las que estamos trabajando,
  podemos entrar la derivada dentro de las integrales

  \begin{align*}
    \frac{d}{d \varepsilon} J(y + \varepsilon h) &= \int_{0}^{L} EI(y''(x) + \varepsilon h''(x)) \cdot h''(x) dx - \int_{0}^{L} q(x)h(x) dx\\
                                                 &= \int_{0}^{L} -q(x)h(x) + EI(y''(x) + \varepsilon h''(x))h''(x) dx
  \end{align*}

  Luego tenemos que
  \begin{equation*}
    \int_{0}^{L} -q(x)h(x) + EIy''(x)h''(x) dx = \frac{d}{d \varepsilon} J(y + \varepsilon h)|_{\varepsilon = 0} = 0
  \end{equation*}

  Considerando $\alpha(x) = -q(x)$ y $\beta(x) = EIy''(x)$ podemos usar el lema,
  pues $q$ es continua por hipótesis e $y$ es continua pues estamos suponiendo que resuelve el problema. Por lo tanto
  concluimos que $EIy''(x) \in \mathcal{C}^{2}([0, L])$ lo que implica que $y \in \mathcal{C}^{4}([0, L])$. Tenemos
  entonces que
  \begin{equation*}
    y^{(4)}(x) = \frac{q(x)}{EI}
  \end{equation*}

  Integrando por partes 2 veces obtenemos
  \begin{equation*}
    \int_{0}^{L} (EIy^{(4)} - q(x))h(x) dx + EIy''(x) \cdot h'(x)|_{x = 0}^{x = L} = 0
  \end{equation*}

  La integral vale $0$, por lo que satisface $y^{(4)}$, notemos que el segundo termino
  de frontera no aparece pues $h(0) = 0 = h(L)$. Por lo tanto tenemos que (dividiendo por $EI$)
  \begin{equation*}
    y''(x) \cdot h'(x)|_{x = 0}^{x = L} = 0
  \end{equation*}

  Necesitaremos un polinomio $P$ de grado $5$ que cumpla
  \begin{align*}
    P(\frac{L}{2}) &= \frac{L}{2}\\
    P'(\frac{L}{2}) &= 1\\
    P''(\frac{L}{2}) &= 0\\
    P(\frac{3L}{4}) &= 0\\
    P'(\frac{3L}{4}) &= 0\\
    P''(\frac{3L}{4}) &= 0
  \end{align*}

  Centrando en $\frac{3L}{4}$ obtenemos que el polinomio a de tener la siguiente forma
  \begin{equation*}
    P(x) = a(x - \frac{3L}{4})^{5} + b(x - \frac{3L}{4})^{4} + c(x - \frac{3L}{4})^{3}
  \end{equation*}

  Calculamos las 2 primeras derivadas
  \begin{gather*}
    P'(x) = 5a(x - \frac{3L}{4})^{4} + 4b(x - \frac{3L}{4})^{3} + 3c(x - \frac{3L}{4})^{2}\\
    P''(x) = 20a(x - \frac{3L}{4})^{3} + 12b(x - \frac{3L}{4})^{2} + 6c(x - \frac{3L}{4})
  \end{gather*}

  Evaluando obtenemos el sistema
  \begin{gather*}
    -a(\frac{L}{4})^{5} + b (\frac{L}{4})^{4} - c(\frac{L}{4})^{3} = \frac{L}{2}\\
    5a (\frac{L}{4})^{4} - 4b (\frac{L}{4})^{3} + 3c (\frac{L}{4})^{2} = 1\\
    -20a (\frac{L}{4})^{3} + 12b (\frac{L}{4})^{2} - 6c \frac{L}{4} = 0
  \end{gather*}

  La solución, usando Wolfram, viene dada por
  \begin{gather*}
    a = -\frac{3840}{L^{4}}\\
    b = -\frac{2368}{L^{3}}\\
    c = -\frac{384}{L^{2}}
  \end{gather*}

  Definimos la función
  \begin{equation*}
    f(x) = \begin{cases}
      x & \text{ si } x \in [0, \frac{L}{2})\\
      P(x) & \text{ si } x \in [\frac{L}{2}, \frac{3L}{4}]\\
      0 & \text{ si } x \in (\frac{3L}{4}, 1]
    \end{cases}
  \end{equation*}

  Esta es $\mathcal{C}^{2}_{0}([0, L])$ por construcción, satisface que $f'(0) = 1$ y $f'(L) = 0$. Tomando $h = f$
  obtenemos que
  \begin{equation*}
    0 = y''(L) \cdot h'(L) - y''(0) \cdot h'(0) = -y''(0) \implies y''(0) = 0
  \end{equation*}

  Luego tomando $h(x) = f(L - x)$, la cual sigue siendo $C^{2}_{0}([0, L])$, pues $f(L - L) = 0$ y $f(L - 0) = 0$,
  obtenemos que
  \begin{equation*}
    0 = y''(L) \cdot f'(L - L) - y''(0) \cdot h'(L - 0) = y''(L)
  \end{equation*}

  Por lo tanto $y$ a de satisfacer
  \begin{equation*}
    \begin{cases}
      y^{(4)}(x) = \frac{q(x)}{EI}\\
      y(0) = 0\\
      y(L) = 0\\
      y''(0) = 0\\
      y''(L) = 0
    \end{cases}
  \end{equation*}
\end{sol}

\begin{sol}
\begin{enumerate}
  \item Verifiquemos que $L(a, b) = k_{1}(k_{2}a - b - k_{3})^{2}$ es convexa.
        Notemos que al ser de clase $\mathcal{C}^{2}$, solo es necesario calcular una de las
        derivadas cruzadas, pues coinciden. Calculemos las derivadas
        \begin{gather*}
          \partial_{a} L(a, b) = 2k_{1}(k_{2}a - b -k_{3}) \cdot k_{2} \implies \partial_{aa}L(a, b) = 2k_{1}k_{2}^{2}\\
          \partial_{b} L(a, b) = -2k_{1}(k_{2}a - b - k_{3}) \implies \partial_{bb} = 2k_{1}\\
          \partial_{ab} L(a, b) = -2k_{1}k_{2}
        \end{gather*}

        Por lo tanto tenemos que el diferencial de $L$ se ve de la siguiente forma
        \begin{equation*}
          DL(a, b) = \begin{bmatrix}
            2k_{1}k_{2}^{2} & -2k_{1}k_{2}\\
            -2k_{1}k_{2}    & 2k_{1}
                     \end{bmatrix}
        \end{equation*}

        Aplicando el criterio de Sylvester tenemos que el primer subdeterminante es $2k_{1}k_{2}^{2} \geq 0$ y
        el determinante de la matriz completa es
        \begin{equation*}
          \det DL(a, b) = 4k_{1}^{2}k_{2}^{2} - 4k_{1}^{2}k_{2}^{2} = 0
        \end{equation*}

        Por lo tanto es una matriz definida semi-positiva, lo que implica que la función es convexa.

  \item Estamos bajo las condiciones del Teorema 4, pues $L(a, b) = k_{1}(k_{2}a - b -k_{3})^{2}$ es convexa
        para todo $a, b \in \RR^{2}$, además estamos trabajando sobre $C = \{y \in \mathcal{C}^{1}([0, T]) \; | \; y(0) = y_{0}\}$. Luego si encontramos una solución a
        \begin{equation*}
        \begin{cases}
          \frac{d}{dx} L_b(y, y') = L_{a}(y, y')\\
          L_{b}(y(T), y'(T)) = 0
        \end{cases}
        \end{equation*}

        Habremos encontrado solución al problema de optimización. Calculemos, de la primera ecuaci\'on tenemos
        \begin{equation*}
          \frac{d}{dx}(-2k_{1}(k_{2}y - y' - k_{3})) = 2k_{1}k_{2}(k_{2}y - y' -k_{3}) \implies -2k_{1}k_{2}y' + 2k_{1}y'' = 2k_{1}k_{2}^{2}y - 2k_{1}k_{2}y' - 2k_{1}k_{2}k_{3}
        \end{equation*}

        Despejando obtenemos
        \begin{equation*}
          2k_{1}y'' = 2k_{1}k_{2}^{2}y - 2k_{1}k_{2}k_{3}
        \end{equation*}

        Esto es una EDO lineal de segundo orden no homegenea. Resolvemos la EDO homogenea primero
        \begin{equation*}
          2k_{1} \lambda^{2} - 2k_{1}k_{2}^{2} = 0 \implies \lambda^{2} = k_{2}^{2}
        \end{equation*}

        Por lo tanto la soluci\'on al problema homogeneo viene dada por
        \begin{equation*}
          y_{h}(x) = C_{1}e^{-k_{2}x} + C_{2}e^{k_{2}x}
        \end{equation*}

        Luego sabemos que la solución viene dada por $y(x) = y_{h}(x) + y_{p}(x)$. La forma de la EDO nos hace
        pensar que $y_{p}(x) = C \in \RR$, provemos esto
        \begin{equation*}
          2k_{1}\cdot 0 = 2k_{1}k_{2}^{2}C - 2k_{1}k_{2}k_{3} \implies C = \frac{k_{3}}{k_{2}}
        \end{equation*}

        Luego la solución a la primera ecuación es
        \begin{equation*}
          y(x) = C_{1}e^{-k_{2}x} + C_{2}e^{k_{2}x} + \frac{k_{3}}{k_{2}}
        \end{equation*}

        Aplicamos las condiciones de borde del conjunto donde $y$ vive.
        \begin{equation*}
          C_{1} + C_{2} + \frac{k_{3}}{k_{2}}= y(0) = y_{0}
        \end{equation*}

        Aplicando la segunda ecuación del Teorema 4 obtenemos que
        \begin{equation*}
          -2k_{1}(k_{2}(C_{1}e^{-k_{2}T} + C_{2}e^{k_{2}T} + \frac{k_{3}}{k_{2}}) - (C_{2}k_{2}e^{k_{2}T} - C_{1}k_{2}e^{-k_{2}T}) - k_{3}) = 0
        \end{equation*}

        Resolviendo
        \begin{gather*}
          -2k_{1}(C_{1}k_{2}e^{-k_{2}T} + C_{2}k_{2}e^{k_{2}} + k_{3} - C_{2}k_{2}e^{k_{2}T} + C_{1}k_{2}e^{-k_{2}T} - k_{3}) = 0\\
          \iff -4C_{1}k_{1}k_{2}e^{-k_{2}T} = 0
        \end{gather*}

        De esto obtenemos que
        \begin{equation*}
          C_{1} = 0
        \end{equation*}

        Reemplazando en la primera ecuación
        \begin{equation*}
          C_{2} = \frac{k_{2}y_{0} - k_{3}}{k_{2}}
        \end{equation*}

        Por lo tanto, dado que $L \in C^{1}([0, T] \times \RR \times \RR)$ y es convexa, tenemos que la solución
        al problema es
        \begin{equation*}
          y(x) = \frac{k_{2}y_{0} - k_{3}}{k_{2}}e^{k_{2}x} + \frac{k_{3}}{k_{2}}
        \end{equation*}

\end{enumerate}
\end{sol}

\begin{sol}
  Sea $x_{0}, x_{1} \in \RR$, tales que $x_{0} < x_{1}$. Supongamos
  $L \in \mathcal{C}^{1}([x_{0}, x_{1}] \times \RR, \times \RR)$. Sea $y \in C^{1}([x_{0}, x_{1}])$ tal que maximice
  el problema, por el lema de fermat tenemos que para $h \in \mathcal{C}^{1}[0, L]$, esto
  pues no hay condiciones de borde y por tanto no necesitamos restringir la perturbación para
  no salirnos del espacio. Se cumple que
  \begin{equation*}
    \lim_{\varepsilon \to 0} \frac{J(y + \varepsilon h) - J(y)}{\varepsilon} = \frac{d}{d\varepsilon} J(y + \varepsilon h)|_{\varepsilon = 0} = 0
  \end{equation*}

  Calculemos, notemos que la derivada puede entrar dentro de la integral dada la regularidad de $L$.
  \begin{align*}
    \frac{d}{d\varepsilon} J(y + \varepsilon h) &= \int_{x_{0}}^{x_{1}} \frac{d}{d\varepsilon} L(x, y + \varepsilon h, y' + \varepsilon h')\\
    &= \int_{x_{0}}^{x_{1}} L_{a}(x, y + \varepsilon h, y' + \varepsilon h') \cdot h + L_{b}(x, y + \varepsilon h, y' + \varepsilon h') \cdot h'
  \end{align*}

  Evaluamos en $0$ e igualamos a $0$.
  \begin{equation*}
    \frac{d}{d\varepsilon} J(y + \varepsilon h) = \int_{x_{0}}^{x_{1}} L_{a}(x, y, y') \cdot h + L_{b}(x, y, y') \cdot h' = 0
  \end{equation*}

  Dado que tenemos este resultado para todo $h \in \mathcal{C}^{1}([x_{0}, x_{1}])$, lo tenemos en particular para
  $h \in \mathcal{C}_{0}^{1}([x_{0}, x_{1}])$. Dado que $L_{a}, L_{b} \in \mathcal{C}([x_{0}, x_{1}])$, podemos usar
  el teorema fundamental del calculo de variaciones (Lema 1) con $\alpha = L_{a}$ y $\beta = L_{b}$. Por lo tanto
  obtenemos que $L_{b} \in \mathcal{C}^{1}$ y que satisface
  \begin{equation*}
    \frac{d}{dx} L_{b}(x, y, y') = L_{a}(x, y, y')
  \end{equation*}

  Con lo que establecemos la primera condición.

  Notemos además que para todo $h \in \mathcal{C}^{1}([x_{0}, x_{1}])$ tenemos que
  \begin{align*}
   0 = \int_{x_{0}}^{x_{1}} (L_{a}(x, y, y')h + L_{b}(x, y , y')h') dx &= \int_{x_{0}}^{x_{1}} (L_{a}(x, y, y') - \frac{d}{dx} L_{b}(x, y, y'))h  dx + L_{b} \cdot h|_{x = x_{0}}^{x = x_{1}}
  \end{align*}

  Dado que lo que esta dentro de la integral es $0$, tenemos que
  \begin{equation*}
    L_{b} \cdot h|_{x = x_{0}}^{x = x_{1}} = 0
  \end{equation*}

  Tomando $h(x) = \frac{x - x_{0}}{x_{1} - x_{0}}$, la cual es $\mathcal{C}^{\infty}$ en el intervalo, obtenemos
  que $L_{b}(x_{1}, y(x_{1}), y'(x_{1})) = 0$, tomando
  $h(x) = \frac{x - x_{1}}{x_{0} - x_{1}}$ obtenemos que $-L_{b}(x_{0}, y(x_{0}), y'(x_{0})) = 0 \implies L_{b}(x_{0}, y(x_{0}), y'(x_{0})) = 0$

  Con lo que tenemos el resultado.
\end{sol}

\begin{sol}
  Recordemos que para una función $f : \RR^{n} \to \RR$ de clase $\mathcal{C}^{1}(\RR^{n})$ es concava si y solamente
  si
  \begin{equation*}
    f(g) \leq f(p) + (\nabla f(p), g - p)_{\RR^{n}}
  \end{equation*}
  Sea $\overline{y}, y \in \mathcal{C}^{1}[x_{0}, x_{1}]$, tal que $\overline{y}$ satisface
  $(3)$.

  Dado que la función $L(x, \cdot, \cdot)$ es concava para todo $x \in [x_{0}, x_{1}]$, tenemos que
  \begin{equation*}
    L(x, y, y') \leq L(x, \overline{y}, \overline{y}') + L_{a}(x, \overline{y}, \overline{y}') \cdot (y - \overline{y}) + L_{b}(x, \overline{y}, \overline{y}') \cdot (y' - \overline{y}')
  \end{equation*}

  Integrando en $[x_{0}, x_{1}]$ tenemos que
  \begin{equation*}
    J(y) \leq J(\overline{y}) + \int_{x_{0}}^{x_{1}} L_{a}(x, \overline{y}, \overline{y}') \cdot (y - \overline{y}) + L_{b}(x, \overline{y}, \overline{y}') (y' - \overline{y}') dx
  \end{equation*}

  Integrando por partes
  \begin{equation*}
     J(y) \leq J(\overline{y}) + \int_{x_{0}}^{x_{1}} (L_{a}(x, \overline{y}, \overline{y}') - \frac{d}{dx} L_{b}(x, \overline{y}, \overline{y}')) \cdot (y - \overline{y}) dx + L_{b}(x, \overline{y}, \overline{y}') \cdot (y - \overline{y})|^{x = x_{1}}_{x = x_{0}}
  \end{equation*}

  Donde la integral es $0$, pues $\overline{y}$ satisface esa ecuación y los términos de borde son $0$, pues $L_{b}(x, \overline{y}, \overline{y}')$ es $0$ en los bordes.

  Por lo tanto
  \begin{equation*}
    J(y) \leq J(\overline{y})
  \end{equation*}

  Es decir, $\overline{y}$ es un máximo.
\end{sol}


\begin{sol}
  Notemos que podemos reescribir el funcional $J$ de la siguiente forma
  \begin{equation*}
    J(y) = \int_{0}^{1} y(x)^{2} + y'(x)^{2} dx + \int_{0}^{1} y(x) \cdot y(x)' dx = \int_{0}^{1} y(x)^{2} + y(x) \cdot y(x)' + y'(x)^{2} dx
  \end{equation*}

  Por lo tanto tenemos que $L(a, b) = a^{2} + ab + b^{2}$, el cual es de clase $\mathcal{C}^{\infty}$. Veamos que los
  extremos del funcional no tienen esquinas. Supongamos que $y \in AC(0,1)$ es solucion con esquinas.
  Luego esta a de satisface las condiciones de Weierstrass-Erdmann. Calculemos la derivada con respecto a $b$ de $L$.
  \begin{equation*}
    L_{b} = a + 2b
  \end{equation*}


  Luego tenemos que la solución a de satisfacer $L_{b}|_{c^{-}} = L_{b}|_{c^{+}}$, es decir
  \begin{equation*}
    y(c^{-}) + 2y'(c^{-}) = y(c^{+}) + 2y'(c^{+}) \implies y'(c^{-}) = y'(c^{+})
  \end{equation*}

  Pues $y(c^{-}) = y(c^{+})$ por la continuidad de $y$, el resultado se obtiene dividiendo por $2$. Por lo tanto
  $y$ no tiene esquinas.

  Verifiquemos que $L$ es convexa, aplicaremos el criterio de Sylvester por lo que tenemos que calcular las derivadas.
  Dado que la función es $\mathcal{C}^{\infty}$, las derivadas cruzadas son iguales
  \begin{align*}
    L_{bb} &= 2\\
    L_{ab} &= 1\\
    L_{aa} &= 2
  \end{align*}

  Luego tenemos que
  \begin{equation*}
    HL(a, b) = \begin{bmatrix} 2 & 1\\ 1 & 2 \end{bmatrix}
  \end{equation*}

  El primer menor es $2 > 0$ y el determinante es $3$, por lo tanto $HL$ es definida semi-positiva por lo que $L$ es convexa.
  Luego basta resolver la ecuación de Euler Lagrange, pues estamos buscando soluciones $\mathcal{C}^{1}$. Notemos que $L_{a} = 2a + b$, luego la ecuación de Euler-Lagrange
  nos queda
  \begin{equation*}
    \frac{d}{dx}(y + 2y') = 2 + 2y' \implies y' + 2y'' = 2y + y' \implies y'' = y
  \end{equation*}

  Resolvemos la EDO mediante el polinomio característico, es decir $\lambda^{2} - 1 = 0$ con lo que obtenemos que
  la solución es
  \begin{equation*}
    y(x) = C_{1}e^{x} + C_{2}e^{-x}
  \end{equation*}

  Aplicando condiciones de borde obtenemos que
  \begin{align*}
    C_{1} + C_{2} &= 0\\
    C_{1}e^{1} + C_{2}e^{-1} &= e^{1} - e^{-1}
  \end{align*}

  Resolviendo (tenemos $C_{1} = -C_{2}$, factorizamos en la ecuación de abajo y obtenemos el resultado) obtenemos que
  \begin{align*}
    C_{1} &= 1\\
    C_{2} &= -1
  \end{align*}

  Por lo tanto tenemos que una solución es $y(x) = e^{x} - e^{-x} = 2 \sinh(x)$
\end{sol}

\begin{sol}
  Notemos que $L \in \mathcal{C}^{2}([x_{0}, x_{1}] \times \RR \times \RR)$. Luego sabemos que los extremos han de
  satisfacer
  \begin{equation*}
    \begin{cases}
      \frac{d}{dx} L_{b} = L_{a}\\
      L_{b}|_{x = c^{-}} = L_{b}|_{x = c^{+}}\\
      (L -y' L_{b})|_{x = c^{-}} = (L - y' L_{b})|_{x = c^{+}}
    \end{cases}
  \end{equation*}

  Notemos que
  \begin{align*}
    L_{a} &= 0\\
    L_{b} &= 4b^{3} - 16b
  \end{align*}

  Por lo tanto queremos que $y$ satisfaga (ctp)
  \begin{equation*}
    \frac{d}{dx} (4(y')^{3} - 16y') = 0
  \end{equation*}

  Luego la edo que nos queda es
  \begin{equation*}
    12(y')^{2} \cdot y'' - 16y'' = 0 \implies (3(y')^{2} - 4)y'' = 0
  \end{equation*}

  Luego una solución, el correspondiente a $y'' = 0$, es $y_{1}(x) = \frac{2}{3}x$. De la otra raiz obtenemos que
  \begin{equation*}
    |y'| = \frac{2}{\sqrt{3}}
  \end{equation*}

  Por lo tanto tenemos que la funci\'on se ve de la siguiente forma, aplicando las condiciones de borde
  \begin{equation*}
    y_{2}(x) = \begin{cases}
      \frac{2}{\sqrt3} x & \text{ si } x \in [0, c]\\
      -\frac{2}{\sqrt{3}} x + \frac{2\sqrt{3} + 6}{\sqrt3} & \text{ si } x \in [c, 3]
    \end{cases}
  \end{equation*}

  Por otra parte
  \begin{equation*}
    y_{3}(x) = \begin{cases}
      -\frac{2}{\sqrt3} x & \text{ si } x \in [0, c]\\
      \frac{2}{\sqrt{3}} x + \frac{2 \sqrt3 - 6}{\sqrt3} & \text{ si } x \in [c, 3]
    \end{cases}
  \end{equation*}

  Estas han de satisfacer
  \begin{equation*}
    L_{b}|_{x = c^{-}} = L_{b}|_{x = c^{+}}
  \end{equation*}

  Es decir
  \begin{equation*}
    4(y'_{2})^{3}(c^{-}) - 16y'_{2}(c^{-}) = 4y'_{2}^{3}(c^{+}) - 16y'_{2}(c^{+})
  \end{equation*}

  Calculamos
  \begin{align*}
    4(\frac{2}{\sqrt{3}})^{3} - \frac{32}{\sqrt{3}} = -4(\frac{2}{3})^{3} + \frac{32}{\sqrt3}
  \end{align*}

  No se satisface, por lo tanto no eran soluciones. A partir de nuevo de $y'' = 0$ obtenemos que podemos
  considerar funciones por tramo de la siguiente forma
  \begin{equation*}
    y_{k} = \begin{cases}
      m_{1,k} x + b_{1,k} & \text { si } x \in [0, c_{k}]\\
      m_{2,k} x + b_{2,k} & \text { si } x \in [c_{k}, 1]
    \end{cases}
  \end{equation*}

  De las condiciones iniciales, obtenemos que $b_{1,k} = 0$ y $b_{2, k} = 2 - 3m_{2,k}$. Es decir las funciones que
  estamos buscando son
  \begin{equation*}
    y_{k} = \begin{cases}
      m_{1,k} x & \text { si } x \in [0, c_{k}]\\
      m_{2,k} (x - 3) + 2 & \text { si } x \in [c_{k}, 1]
    \end{cases}
  \end{equation*}

  Queremos además que satisfagan las ecuaciones de esquina.
  Calculemos $L - bL_{b}$
  \begin{equation*}
    L - bL_{b} = b^{4} - 8b^{2} - b(4b^{3} - 16b) = 8b^{2}- 3b^{4}
  \end{equation*}

  Notemos que esta función es simétrica respecto al eje $y$, por lo que si queremos que se llegue a satisfacer
  la ecuación necesitaremos $m_{1,k} = -m_{2,k}$. La siguiente ecuación de esquina nos dice

  \begin{equation*}
    4m_{1,k}^{3} - 16m_{1,k} = -4m_{1,k}^{3} + 16m_{1,k} \implies 8m_{1,k}^{3} - 32m_{1,k} = 0 \implies m_{1,k}(m_{1,k}^{2} - 4)
  \end{equation*}

  Por lo tanto necesitamos $|m_{1,k}| = 2$. Apliquemos la condición de continuidad
  \begin{align*}
    2c_{2} = -2(c_{2} - 3) + 2 \implies c_{2} &= 2\\
    -2c_{3} = 2(c_{3} - 3) + 2 \implies c_{3} &= 1
  \end{align*}


  Por lo tanto las dos soluciones que nos faltaban eran
  \begin{align*}
    y_{2} &= \begin{cases}
      2x & \text{ si } x \in [0, 2]\\
      -2(x - 3) + 2 & \text{ si } x \in [2, 3]
    \end{cases}\\
    y_{3} &= \begin{cases}
      -2x & \text{ si } x \in [0, 1]\\
      2(x - 3) + 2 & \text{ si } x \in [1, 3]
    \end{cases}
  \end{align*}
\end{sol}

\end{document}
